{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kunden Match <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.) b.) Loading datasets <a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Fuzzy Match.xlsx'\n",
    "\n",
    "#Salesforce Sheet\n",
    "df_salesforce = pd.read_excel(file_path, sheet_name = 'Salesforce')\n",
    "#Steps Sheet\n",
    "df_steps = pd.read_excel(file_path, sheet_name = 'Steps')\n",
    "#df_steps.head()\n",
    "#df_salesforce.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##check this at the end when putting in the IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in entries: 2124\n",
      "Percentage difference: 47.53%\n"
     ]
    }
   ],
   "source": [
    "# Number of entries in each DataFrame\n",
    "\n",
    "#coutnumer of rows\n",
    "entries_steps = 6593\n",
    "entries_salesforce = 4469\n",
    "\n",
    "# Calculate the difference in entries. \n",
    "difference = entries_steps - entries_salesforce\n",
    "percentage_difference = (difference / entries_salesforce) * 100\n",
    "print(f\"Difference in entries: {difference}\")\n",
    "print(f\"Percentage difference: {percentage_difference:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) Data manipulation for analysis<a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) a.) Creating a concatenated \"address\" column for Steps<a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data type of the 'Zip Code' column\n",
    "zip_code_dtype = df_steps['Zip Code'].dtype\n",
    "#'Zip Code'is a float that cannot be matched. For the string matching it will be transformed into a string\n",
    "\n",
    "# Convert 'Zip Code', 'Street' and 'City' column in df_steps to string\n",
    "df_steps['Zip Code'] = df_steps['Zip Code'].astype(str)\n",
    "df_steps['Street'] = df_steps['Street'].astype(str)\n",
    "df_steps['City'] = df_steps['City'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new column \"Address\" for both Salesforce and Steps\n",
    "Create a concatenated address column to prepare the fuzzy string match. Therefore, the three columns Street, Zip Code, and City are concatenated in the new column 'Address'. Spaces are ignored - In this analysis, they don't add value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       nannannan\n",
       "1              Vredener Straße 4148703.0Stadtlohn\n",
       "2        Kirchnerstraße 460311.0Frankfurt am Main\n",
       "3               Stuttgarter Straße 2668782.0Brühl\n",
       "4                   Eilbeker Weg 1622089.0Hamburg\n",
       "                          ...                    \n",
       "6588    Mannheimer Straße 22955543.0Bad Kreuznach\n",
       "6589                   Lindenstr. 3917389.0Anklam\n",
       "6590                      Worthweg 529693.0Ahlden\n",
       "6591          Donnerburgweg 4038106.0Braunschweig\n",
       "6592                    Liebenau 364252.0Liebenau\n",
       "Name: Steps_Address, Length: 6593, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_steps['Steps_Address'] = df_steps['Street'] + df_steps['Zip Code'] + df_steps['City']\n",
    "# df_steps['Steps_Address'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) b.) Creating a concatenated \"address\" column for Salesforce<a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Billing ZIP'is a float that cannot be matched. For the string matching it will be transformed into a string\n",
    "df_salesforce['Billing Street'] = df_salesforce['Billing Street'].astype(str)\n",
    "df_salesforce['Street Number'] = df_salesforce['Street Number'].astype(str)\n",
    "df_salesforce['Billing ZIP'] = df_salesforce['Billing ZIP'].astype(str)\n",
    "df_salesforce['Billing City'] = df_salesforce['Billing City'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salesforce['Salesforce_Address'] = df_salesforce['Billing Street'] + df_salesforce['Street Number'] + df_salesforce['Billing ZIP'] + df_salesforce['Billing City'] \n",
    "#df_salesforce['Salesforce_Address'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) c.) Separating filled Steps ID<a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Check how many Salesforce IDs are assigned a Steps ID. \n",
    "\n",
    "(1) This is relevant to exclude the IDs that were filled. \"Einige wenige Kunden wurden bereits zwischen den Systemen gematcht, d.h. einer Salesforce-ID wurde eine Steps-ID zugewiesen.\"\n",
    "(2) Fuzzywuzzy library expects non-null string inputs. Keeping in mind, if a null value is encountered, it could lead to errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1067\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Which Step IDs aren't filled?\n",
    "null_StepsID = df_salesforce['Steps ID'][df_salesforce['Steps ID'].isna()]\n",
    "\n",
    "# To separate them for the string match, save the filled and non-filled ones as a new columns\n",
    "df_salesforce['Filled_StepsID'] = df_salesforce['Steps ID'].where(df_salesforce['Steps ID'].notna())\n",
    "df_salesforce['Manual_StepsID'] = df_salesforce['Steps ID'].where(df_salesforce['Steps ID'].isna())\n",
    "\n",
    "# Validate the if the separation worked\n",
    "print(df_salesforce['Filled_StepsID'].count()) #1067 Step IDs are already matched\n",
    "print(df_salesforce['Manual_StepsID'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match these back when completed the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the best match for each Salesforce address in Steps DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snippet 1: Issue with this code: Figured there are missing and non-string (e.g. ZIP code) values. Elements used to create both Salesforce_Address or Steps_Address have non-string values and contain NaN values. There was a TypeError as process.extractOne() expected a strings or byte-like object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) Fuzzy String Match<a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) a.) Matching Salesforce and Steps concatenated addresses<a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match(salesforce_address, steps_address):\n",
    "    best_match = process.extractOne(salesforce_address, steps_address, scorer=fuzz.token_sort_ratio)\n",
    "    return best_match\n",
    "\n",
    "# Apply the function to find matches\n",
    "matches = df_salesforce['Salesforce_Address'].apply(find_best_match, steps_address = df_steps['Steps_Address'])\n",
    "\n",
    "# Extract matched addresses and scores\n",
    "df_salesforce['First_Best_Match_Address'] = matches.apply(lambda x: x[0] if x and x[1] >= 95 else None)\n",
    "df_salesforce['First_Match_Score'] = matches.apply(lambda x: x[1] if x else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Match Address column df_salesforce DataFrame is empty. \n",
    "This indicates there weren't matches with a score of 95% or higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mode for the first match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode of Match Scores: 0    51\n",
      "Name: First_Match_Score, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "first_match_score_mode = df_salesforce['First_Match_Score'].mode()\n",
    "print(f\"Mode of Match Scores: {first_match_score_mode}\")\n",
    "#first_frequency_table = df_salesforce['First_Match_Score'].value_counts().sort_index()\n",
    "\n",
    "# Display the frequency table\n",
    "#print(\"Frequency table of Match Scores:\")\n",
    "#print(first_frequency_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) b.) Excluding special characters<a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special characters using RegEx to the 'Street' column in both df\n",
    "df_steps['Steps_Address'] = df_steps['Steps_Address'].str.replace(r'[ \\-./]', '', regex = True)\n",
    "df_salesforce['Salesforce_Address'] = df_salesforce['Salesforce_Address'].str.replace(r'[ \\-./]', '', regex = True)\n",
    "\n",
    "# Display the DataFrame\n",
    "#print(df_steps['Steps_Address'])\n",
    "#print(df_salesforce['Salesforce_Address'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2: Apply the Matching Function to Find Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to find matches\n",
    "matches = df_salesforce['Salesforce_Address'].apply(find_best_match, steps_address = df_steps['Steps_Address'])\n",
    "\n",
    "# Extract matched addresses and scores\n",
    "df_salesforce['Second_Best_Match_Address'] = matches.apply(lambda x: x[0] if x and x[1] >= 95 else None)\n",
    "df_salesforce['Second_Match_Score'] = matches.apply(lambda x: x[1] if x else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the additional strings (\"str\", \"straße\", \"strasse\") from the addresses in both DataFrames and then applying the matching function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the additional strings (\"str\", \"straße\", \"strasse\") from the addresses using Regex\n",
    "names_to_remove = ['straße', 'str', 'strasse']\n",
    "pattern = '|'.join(names_to_remove)\n",
    "\n",
    "# Using Regex to remove names from columns\n",
    "df_salesforce['Salesforce_Address'] = df_salesforce['Salesforce_Address'].str.replace(pattern, '', case=False, regex=True)\n",
    "df_steps['Steps_Address'] = df_steps['Steps_Address'].str.replace(pattern, '', case=False, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to find matches\n",
    "matches = df_salesforce['Salesforce_Address'].apply(find_best_match, steps_address = df_steps['Steps_Address'])\n",
    "\n",
    "# Extract matched addresses and scores\n",
    "df_salesforce['Third_Best_Match_Address'] = matches.apply(lambda x: x[0] if x and x[1] >= 95 else None)\n",
    "df_salesforce['Third_Match_Score'] = matches.apply(lambda x: x[1] if x else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Account Name (Salesforce) / Customer Name (Steps)\n",
    "-> clean the addresses by removing specified characters and substrings from the columns \"Account Name\" in df_salesforce and \"Customer Name\" in df_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the Function to Clean the Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex pattern for the special characters to remove\n",
    "pattern = r\"[ \\-\\.\\&\\?\\*\\«\\»\\/\\+\\·\\(\\)\\s®©!:,]\"\n",
    "\n",
    "# Remove the characters from 'Account Name' column in df_salesforce\n",
    "df_salesforce['Cleaned_Account Name'] = df_salesforce['Account Name'].str.replace(pattern, '', regex=True)\n",
    "#print(df_salesforce['Cleaned_Account Name'])\n",
    "\n",
    "# Remove the characters from 'Customer Name' column in df_steps\n",
    "df_steps['Cleaned_Customer Name'] = df_steps['Customer Name'].str.replace(pattern, '', regex=True)\n",
    "#print(df_steps['Cleaned_Customer Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate addresses with Account Name and Customer Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate 'Cleaned_Account Name' with 'Salesforce_Address'\n",
    "df_salesforce['Salesforce_Address'] = df_salesforce['Cleaned_Account Name'] + df_salesforce['Salesforce_Address']\n",
    "#print(df_salesforce['Salesforce_Address'].head(10))\n",
    "# Concatenate 'Cleaned_Customer Name' with 'Steps_Address'\n",
    "df_steps['Steps_Address'] = df_steps['Cleaned_Customer Name'] + df_steps['Steps_Address']\n",
    "#print(df_steps['Steps_Address'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to find matches\n",
    "matches = df_salesforce['Salesforce_Address'].apply(find_best_match, steps_address = df_steps['Steps_Address'])\n",
    "\n",
    "# Extract matched addresses and scores\n",
    "df_salesforce['Fourth_Best_Match_Address'] = matches.apply(lambda x: x[0] if x and x[1] >= 95 else None)\n",
    "df_salesforce['Fourth_Match_Score'] = matches.apply(lambda x: x[1] if x else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing legal forms and special characters from Account Name and Customer Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_forms = [\n",
    "    \"kg\", \"e. k.\", \"e.K.\", \"gmbh\", \"GmbH \\+ Co\\. KG\", \"GmbH & Co\\. KG\",\n",
    "    \"e.Kfr\\.\", \"e\\.V\\.\", \"AG\", \"ohg\", \"UG\", \"haftungsbeschränkt\",\n",
    "    \"KG\", \"SE\", \"GbR\", \"GmbH&Co\\.KG\", \"e\\.U\\.\", \"a\\.G\\.\", \"a\\. G\\.\", \n",
    "    \"m\\.b\\.H\\.\", \"Inc\\.\", \"B\\.V\\.\"\n",
    "]\n",
    "\n",
    "# Combine legal forms into a regex pattern\n",
    "legal_forms_pattern = r\"\\b(?:{})\\b\".format('|'.join(re.escape(form) for form in legal_forms))\n",
    "\n",
    "# Function to clean text by removing legal forms\n",
    "def clean_text(text, pattern):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
    "    return text.strip()\n",
    "\n",
    "# Clean 'Salesforce_Address' in df_salesforce\n",
    "df_salesforce['Cleaned_Salesforce_Address'] = df_salesforce['Salesforce_Address'].apply(clean_text, args=(legal_forms_pattern,))\n",
    "\n",
    "# Clean 'Steps_Address' in df_steps\n",
    "df_steps['Cleaned_Steps_Address'] = df_steps['Steps_Address'].apply(clean_text, args=(legal_forms_pattern,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to find matches\n",
    "matches = df_salesforce['Salesforce_Address'].apply(find_best_match, steps_address = df_steps['Steps_Address'])\n",
    "\n",
    "# Extract matched addresses and scores\n",
    "df_salesforce['Fifth_Best_Match_Address'] = matches.apply(lambda x: x[0] if x and x[1] >= 95 else None)\n",
    "df_salesforce['Fifth_Match_Score'] = matches.apply(lambda x: x[1] if x else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from address to Steps ID\n",
    "address_to_id = dict(zip(df_salesforce['Fifth_Best_Match_Address'], df_steps['Steps ID']))\n",
    "\n",
    "# Only keep the Steps ID if the Match Score is 90% or higher\n",
    "df_salesforce['Filled_Steps_ID'] = df_salesforce.apply(\n",
    "    lambda row: address_to_id[row['Fifth_Best_Match_Address']] if row['Fifth_Match_Score'] >= 90 else row['Steps ID'],\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been exported to C:\\Users\\Katha\\Documents\\Job application documents\\Data Analyst application\\Case Studies\\Rapid Data\\df_salesforce.xlsx\n"
     ]
    }
   ],
   "source": [
    "output_file = r'C:\\Users\\Katha\\Documents\\Job application documents\\Data Analyst application\\Case Studies\\Rapid Data\\df_salesforce.xlsx'\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "df_salesforce.to_excel(output_file, index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"DataFrame has been exported to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
