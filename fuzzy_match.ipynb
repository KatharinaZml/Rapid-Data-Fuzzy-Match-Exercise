{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kunden Match <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation<a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading datasets <a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Fuzzy Match.xlsx'\n",
    "\n",
    "#Salesforce Sheet\n",
    "df_salesforce = pd.read_excel(file_path, sheet_name = 'Salesforce')\n",
    "#Steps Sheet\n",
    "df_steps = pd.read_excel(file_path, sheet_name = 'Steps')\n",
    "#df_steps.head()\n",
    "#df_salesforce.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in entries: 2124\n",
      "Percentage difference: 47.53%\n"
     ]
    }
   ],
   "source": [
    "# Number of entries in each DataFrame\n",
    "\n",
    "# Count the number of rows\n",
    "entries_steps = 6593\n",
    "entries_salesforce = 4469\n",
    "\n",
    "# Calculate the difference in entries. \n",
    "difference = entries_steps - entries_salesforce\n",
    "percentage_difference = (difference / entries_salesforce) * 100\n",
    "print(f\"Difference in entries: {difference}\")\n",
    "print(f\"Percentage difference: {percentage_difference:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) Data manipulation for analysis<a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) a.) Creating a concatenated \"address\" column for Steps<a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data type of the 'Zip Code' column\n",
    "zip_code_dtype = df_steps['Zip Code'].dtype\n",
    "\n",
    "#'Zip Code'is a float that cannot be matched. \n",
    "# For the string matching it will be transformed into a string\n",
    "\n",
    "# Convert 'Zip Code', 'Street' and 'City' column in df_steps to string\n",
    "df_steps['Zip Code'] = df_steps['Zip Code'].astype(str)\n",
    "df_steps['Street'] = df_steps['Street'].astype(str)\n",
    "df_steps['City'] = df_steps['City'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new column \"Address\" for both Salesforce and Steps\n",
    "Create a concatenated address column to prepare the fuzzy string match. \n",
    "The three columns Street, Zip Code, and City are concatenated in the new column 'Address'. Spaces are ignored - In this analysis, they don't add value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steps['Steps_Address'] = df_steps['Street'] + df_steps['Zip Code'] + df_steps['City']\n",
    "# df_steps['Steps_Address'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) b.) Creating a concatenated \"address\" column for Salesforce<a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Billing ZIP'is a float that cannot be matched. For the string matching it will be transformed into a string\n",
    "df_salesforce['Billing Street'] = df_salesforce['Billing Street'].astype(str)\n",
    "df_salesforce['Street Number'] = df_salesforce['Street Number'].astype(str)\n",
    "df_salesforce['Billing ZIP'] = df_salesforce['Billing ZIP'].astype(str)\n",
    "df_salesforce['Billing City'] = df_salesforce['Billing City'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salesforce['Salesforce_Address'] = df_salesforce['Billing Street'] + df_salesforce['Street Number'] + df_salesforce['Billing ZIP'] + df_salesforce['Billing City'] \n",
    "#df_salesforce['Salesforce_Address'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) c.) Separating filled Steps ID<a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking how many Salesforce IDs are assigned a Steps ID. \n",
    "\n",
    "This is relevant to exclude the IDs that were filled. \"Einige wenige Kunden wurden bereits zwischen den Systemen gematcht, d.h. einer Salesforce-ID wurde eine Steps-ID zugewiesen.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1067\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Which Step IDs aren't filled?\n",
    "#null_StepsID = df_salesforce['Steps ID'][df_salesforce['Steps ID'].isna()]\n",
    "\n",
    "# To separate them for the string match, save the filled and non-filled ones as a new columns\n",
    "#df_salesforce['Filled_StepsID'] = df_salesforce['Steps ID'].where(df_salesforce['Steps ID'].notna())\n",
    "#df_salesforce['Manual_StepsID'] = df_salesforce['Steps ID'].where(df_salesforce['Steps ID'].isna())\n",
    "\n",
    "# Validate the if the separation worked\n",
    "#print(df_salesforce['Filled_StepsID'].count()) #1067 Step IDs are already matched\n",
    "#print(df_salesforce['Manual_StepsID'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) Fuzzy String Match<a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuzzy String Matching algorithm determines how close elements of string are. \n",
    "This is discovered by finding the minimum number of “edits” needed to transform one string to another (\"edit distance\"). An edit is an operation performed on a string to transform it into another string. The four edit types are: (1) insert, (2) delete, (3) switch, (4) replace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. a) Matching Salesforce and Steps concatenated addresses <a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Token sort ratio:\n",
    "Checks how similar words in the string new \"address\" column are. The order of the words is ignored to determine how similar they are.\n",
    "\n",
    "(2) process.extractOne\"\n",
    "The dataset shows words are spelled differently. Exact string matching is not feasible.  Given the inconsistencies in data entries, \"process.extractOne\" method is used to find the closest correct spelling for a misspelled word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match(salesforce_address, steps_address):\n",
    "    best_match = process.extractOne(salesforce_address, steps_address, scorer=fuzz.token_sort_ratio)\n",
    "    return best_match\n",
    "\n",
    "# Apply the function to find matches\n",
    "matches = df_salesforce['Salesforce_Address'].apply(find_best_match, steps_address = df_steps['Steps_Address'])\n",
    "\n",
    "# Extract matched addresses and their scores\n",
    "df_salesforce['First_Best_Match_Address'] = matches.apply(lambda x: x[0] if x and x[1] >= 95 else None)\n",
    "df_salesforce['First_Match_Score'] = matches.apply(lambda x: x[1] if x else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. b) Removing special characters from concatenated addresses <a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special characters using RegEx to the 'Street' column in both df\n",
    "df_steps['Steps_Address'] = df_steps['Steps_Address'].str.replace(r'[ \\-./]', '', regex = True)\n",
    "df_salesforce['Salesforce_Address'] = df_salesforce['Salesforce_Address'].str.replace(r'[ \\-./]', '', regex = True)\n",
    "\n",
    "# Display the DataFrame\n",
    "#print(df_steps['Steps_Address'])\n",
    "#print(df_salesforce['Salesforce_Address'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the Matching Function to Find Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to find matches (Function was defined in 2. a)\n",
    "matches = df_salesforce['Salesforce_Address'].apply(find_best_match, steps_address = df_steps['Steps_Address'])\n",
    "\n",
    "# Extract the matched addresses and their scores\n",
    "# matches format (\"matched address\", score)\n",
    "# x[0] = is the best matched steps address, x[1] = is the score , saved in df_salesforce\n",
    "df_salesforce['Second_Best_Match_Address'] = matches.apply(lambda x: x[0] if x and x[1] >= 95 else None)\n",
    "df_salesforce['Second_Match_Score'] = matches.apply(lambda x: x[1] if x else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. c) Removing additional strings from addresses <a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the additional strings (\"str\", \"straße\", \"strasse\") from the addresses in both DataFrames and then applying the matching function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the additional strings (\"str\", \"straße\", \"strasse\") from the addresses using Regex by by joining the list of strings\n",
    "names_to_remove = ['straße', 'str', 'strasse']\n",
    "pattern = '|'.join(names_to_remove)\n",
    "\n",
    "# Using Regex to remove names from columns\n",
    "df_salesforce['Salesforce_Address'] = df_salesforce['Salesforce_Address'].str.replace(pattern, '', case=False, regex=True)\n",
    "df_steps['Steps_Address'] = df_steps['Steps_Address'].str.replace(pattern, '', case=False, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to find matche\n",
    "matches = df_salesforce['Salesforce_Address'].apply(find_best_match, steps_address = df_steps['Steps_Address'])\n",
    "\n",
    "# Extract the matched addresses and their scores\n",
    "df_salesforce['Third_Best_Match_Address'] = matches.apply(lambda x: x[0] if x and x[1] >= 95 else None)\n",
    "df_salesforce['Third_Match_Score'] = matches.apply(lambda x: x[1] if x else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. d) Remove special characters from Account and Customer Names <a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Account Name (Salesforce) / Customer Name (Steps)\n",
    "#-> Clean the addresses by removing specified characters and substrings from the columns \"Account Name\" in df_salesforce and \"Customer Name\" in df_steps\n",
    "# Regex pattern to remove special characters \n",
    "pattern = r\"[ \\-\\.\\&\\?\\*\\«\\»\\/\\+\\·\\(\\)\\s®©!:,]\"\n",
    "\n",
    "# Removing the characters from 'Account Name' column in df_salesforce\n",
    "df_salesforce['Cleaned_Account Name'] = df_salesforce['Account Name'].str.replace(pattern, '', regex=True)\n",
    "#print(df_salesforce['Cleaned_Account Name'])\n",
    "\n",
    "# Removing the characters from 'Customer Name' column in df_steps\n",
    "df_steps['Cleaned_Customer Name'] = df_steps['Customer Name'].str.replace(pattern, '', regex=True)\n",
    "#print(df_steps['Cleaned_Customer Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the addresses with Account Name and Customer Name to see if the score is higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate 'Cleaned_Account Name' with 'Salesforce_Address'\n",
    "df_salesforce['Salesforce_Address'] = df_salesforce['Cleaned_Account Name'] + df_salesforce['Salesforce_Address']\n",
    "#print(df_salesforce['Salesforce_Address'].head(10))\n",
    "# Concatenate 'Cleaned_Customer Name' with 'Steps_Address'\n",
    "df_steps['Steps_Address'] = df_steps['Cleaned_Customer Name'] + df_steps['Steps_Address']\n",
    "#print(df_steps['Steps_Address'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to find the matches\n",
    "matches = df_salesforce['Salesforce_Address'].apply(find_best_match, steps_address = df_steps['Steps_Address'])\n",
    "\n",
    "# Extract matched addresses and their scores\n",
    "df_salesforce['Fourth_Best_Match_Address'] = matches.apply(lambda x: x[0] if x and x[1] >= 95 else None)\n",
    "df_salesforce['Fourth_Match_Score'] = matches.apply(lambda x: x[1] if x else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. e) Removing legal forms from Account and Customer Names <a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_forms = [\n",
    "    \"kg\", \"e. k.\", \"e.K.\", \"gmbh\", \"GmbH \\+ Co\\. KG\", \"GmbH & Co\\. KG\",\n",
    "    \"e.Kfr\\.\", \"e\\.V\\.\", \"AG\", \"ohg\", \"UG\", \"haftungsbeschränkt\",\n",
    "    \"KG\", \"SE\", \"GbR\", \"GmbH&Co\\.KG\", \"e\\.U\\.\", \"a\\.G\\.\", \"a\\. G\\.\", \n",
    "    \"m\\.b\\.H\\.\", \"Inc\\.\", \"B\\.V\\.\"\n",
    "]\n",
    "\n",
    "# Combine legal the forms into a Regex pattern\n",
    "legal_forms_pattern = r\"\\b(?:{})\\b\".format('|'.join(re.escape(form) for form in legal_forms))\n",
    "\n",
    "# Cleaning text by removing its legal forms\n",
    "def clean_text(text, pattern):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
    "    return text.strip()\n",
    "\n",
    "# Clean 'Salesforce_Address' in df_salesforce\n",
    "df_salesforce['Cleaned_Salesforce_Address'] = df_salesforce['Salesforce_Address'].apply(clean_text, args=(legal_forms_pattern,))\n",
    "\n",
    "# Clean 'Steps_Address' in df_steps\n",
    "df_steps['Cleaned_Steps_Address'] = df_steps['Steps_Address'].apply(clean_text, args=(legal_forms_pattern,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to find matches\n",
    "matches = df_salesforce['Salesforce_Address'].apply(find_best_match, steps_address = df_steps['Steps_Address'])\n",
    "\n",
    "# Extract matched addresses and its scores\n",
    "df_salesforce['Fifth_Best_Match_Address'] = matches.apply(lambda x: x[0] if x and x[1] >= 95 else None)\n",
    "df_salesforce['Fifth_Match_Score'] = matches.apply(lambda x: x[1] if x else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. f) Mapping and matching the score  <a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from address to Steps ID ; Pairing each element with the corresponding element\n",
    "address_to_id = dict(zip(df_salesforce['Fifth_Best_Match_Address'], df_steps['Steps ID']))\n",
    "\n",
    "# Only keep the Steps ID if the Match Score is or is greater than 90%\n",
    "df_salesforce['Filled_Steps_ID'] = df_salesforce.apply(lambda row: address_to_id[row['Fifth_Best_Match_Address']] if row['Fifth_Match_Score'] >= 90 else row['Steps ID'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.) Export Fuzzy String Match as .xlsx <a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been exported to C:\\Users\\Katha\\Documents\\Job application documents\\Data Analyst application\\Case Studies\\Rapid Data\\df_salesforce.xlsx\n"
     ]
    }
   ],
   "source": [
    "output_file = r'C:\\Users\\Katha\\Documents\\Job application documents\\Data Analyst application\\Case Studies\\Rapid Data\\df_salesforce.xlsx'\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "df_salesforce.to_excel(output_file, index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"DataFrame has been exported to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
